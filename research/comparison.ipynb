{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"классическое\" обучение - без распределенных вычислений на сжатых фичах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pathlib\n",
    "cwd = pathlib.Path().cwd()\n",
    "sys.path.append(cwd.parent.as_posix())\n",
    "data_folder = cwd.parent.joinpath('data')\n",
    "\n",
    "import logging\n",
    "import json\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from telecom.transformers import ColumnsCorrector, TimeDifference, Clusterer, Merger, AsDummies, PurchaseRatio, BasicFiller\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "\n",
    "from auxiliary import cv_fit, whole_fit, cv_compare\n",
    "from functools import partial\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "# from catboost import CatBoostClassifier\n",
    "\n",
    "FORMAT = '%(asctime)s > %(message)s'\n",
    "logging.basicConfig(filename='fit.log', level=logging.INFO, format=FORMAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic parameters\n",
    "bound_date = '2018-11-19'\n",
    "n_folds = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read train data\n",
    "train_data = pd.read_csv(data_folder.joinpath('data_train.csv')).drop('Unnamed: 0', axis=1)\n",
    "# extract required train data\n",
    "train_data = train_data[train_data['buy_time'] >= dt.datetime.fromisoformat('2018-11-19').timestamp()]\n",
    "# data/target split\n",
    "data = train_data.drop('target', axis=1)\n",
    "target = train_data['target']\n",
    "\n",
    "# read compressed features\n",
    "features = pd.read_csv(data_folder.joinpath('compressed_features.csv'))\n",
    "\n",
    "# calc class weights\n",
    "class_weights = dict(enumerate(compute_class_weight('balanced', classes=[0, 1], y=train_data['target'])))\n",
    "# prepare folds for CV fit\n",
    "folds = KFold(n_splits=n_folds, shuffle=True, random_state=29)\n",
    "# prepare scoring function\n",
    "f1_macro = partial(f1_score, average='macro')\n",
    "\n",
    "# prepare estimators list\n",
    "estimators = [\n",
    "    SGDClassifier(random_state=17, n_jobs=-1, class_weight=class_weights),\n",
    "    GradientBoostingClassifier(random_state=17, loss='deviance'),\n",
    "    RandomForestClassifier(random_state=17, class_weight=class_weights, n_jobs=-1),\n",
    "    LGBMClassifier(random_state=17, class_weight=class_weights, n_jobs=-1),\n",
    "    XGBClassifier(random_state=17),\n",
    "    # CatBoostClassifier(random_state=17, logging_level='Silent', allow_writing_files=False)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## basic pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "preparer = make_pipeline(\n",
    "    # Merger(features, method='nearest', fillna='default'),\n",
    "    Merger(features, method='backward', fillna='mean'),\n",
    "    # Merger(features, method='backward', fillna='nearest'),\n",
    "    TimeDifference('feats_time', 'train_time'),\n",
    "\n",
    "    Clusterer(['0', '1', '2'], n_clusters=8, random_state=13),\n",
    "    # AsDummies(['cluster']),\n",
    "    PurchaseRatio(by=['cluster']),\n",
    "\n",
    "    ColumnsCorrector('drop', ['id', 'train_time', 'feats_time',]),\n",
    "    BasicFiller(strategy='mean', apply_on_fly=True),\n",
    ")\n",
    "\n",
    "# METHOD_PREFIX = 'NEAREST'\n",
    "METHOD_PREFIX = 'BACKWARD+MEAN'\n",
    "# METHOD_PREFIX = 'BACKWARD+NEAREST'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # cross-validation fit, apply pipeline on whole data before splitting: the results in general are the same as for CVFIT\n",
    "# prepared = preparer.fit_transform(data, target)\n",
    "# for est in estimators:\n",
    "#     cv_fit(est, prepared, target, cv=folds, scorer=f1_macro, logger=logging, prefix=f'[CVPRE] [{METHOD_PREFIX}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CVFIT] [BACKWARD+MEAN] SGDClassifier: 0.4250944480257971\n",
      "[CVFIT] [BACKWARD+MEAN] GradientBoostingClassifier: 0.6066857389151871\n",
      "[CVFIT] [BACKWARD+MEAN] RandomForestClassifier: 0.7393420823022738\n",
      "[CVFIT] [BACKWARD+MEAN] LGBMClassifier: 0.7533358612482944\n",
      "[CVFIT] [BACKWARD+MEAN] XGBClassifier: 0.6385783049200079\n"
     ]
    }
   ],
   "source": [
    "# cross-validation fit (apply pipeline to train/valid separately) - it is logically the most correct way\n",
    "for est in estimators:\n",
    "    cv_fit(est, data, target, cv=folds, pipe=preparer, scorer=f1_macro, logger=logging, prefix=f'[CVFIT] [{METHOD_PREFIX}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fit on whole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WHOLE] [BACKWARD+NEAREST] SGDClassifier: 0.46482219297679356\n",
      "[WHOLE] [BACKWARD+NEAREST] GradientBoostingClassifier: 0.5579754575825518\n",
      "[WHOLE] [BACKWARD+NEAREST] RandomForestClassifier: 0.8261811848099537\n",
      "[WHOLE] [BACKWARD+NEAREST] LGBMClassifier: 0.7387400692796617\n",
      "[WHOLE] [BACKWARD+NEAREST] XGBClassifier: 0.6481633960305903\n"
     ]
    }
   ],
   "source": [
    "# # fit and validate on whole data\n",
    "# for est in estimators:\n",
    "#     whole_fit(est, data, target, pipe=preparer, scorer=f1_macro, logger=logging, prefix=f'[WHOLE] [{METHOD_PREFIX}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parse logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAST_LINES = len(estimators) * 3\n",
    "\n",
    "with open('fit.log', 'r') as logs:\n",
    "    lines = [line.strip().replace(':', '').split()[-4:] for line in logs.readlines()[-LAST_LINES:]]\n",
    "result = pd.DataFrame(lines, columns=['ftype', 'mtype', 'name', 'score'])\n",
    "# result.to_csv(data_folder.joinpath('cvfit_compare.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = pd.read_csv(data_folder.joinpath('cvfit_compare.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ftype</th>\n",
       "      <th>mtype</th>\n",
       "      <th>name</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[CVFIT]</td>\n",
       "      <td>[BACKWARD+MEAN]</td>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.7534617117595721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[CVFIT]</td>\n",
       "      <td>[BACKWARD+MEAN]</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.7393420823022738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[CVFIT]</td>\n",
       "      <td>[NEAREST]</td>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.7376994846703424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[CVFIT]</td>\n",
       "      <td>[BACKWARD+NEAREST]</td>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.7376726747992317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[CVFIT]</td>\n",
       "      <td>[BACKWARD+NEAREST]</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.7204945029996006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ftype               mtype                    name               score\n",
       "8   [CVFIT]     [BACKWARD+MEAN]          LGBMClassifier  0.7534617117595721\n",
       "7   [CVFIT]     [BACKWARD+MEAN]  RandomForestClassifier  0.7393420823022738\n",
       "13  [CVFIT]           [NEAREST]          LGBMClassifier  0.7376994846703424\n",
       "3   [CVFIT]  [BACKWARD+NEAREST]          LGBMClassifier  0.7376726747992317\n",
       "2   [CVFIT]  [BACKWARD+NEAREST]  RandomForestClassifier  0.7204945029996006"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# overview top5\n",
    "result.sort_values('score', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>name</th>\n",
       "      <th>GradientBoostingClassifier</th>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <th>SGDClassifier</th>\n",
       "      <th>XGBClassifier</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mtype</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>[BACKWARD+MEAN]</th>\n",
       "      <td>0.606686</td>\n",
       "      <td>0.753462</td>\n",
       "      <td>0.739342</td>\n",
       "      <td>0.425094</td>\n",
       "      <td>0.638578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[BACKWARD+NEAREST]</th>\n",
       "      <td>0.580423</td>\n",
       "      <td>0.737673</td>\n",
       "      <td>0.720495</td>\n",
       "      <td>0.437933</td>\n",
       "      <td>0.622540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>[NEAREST]</th>\n",
       "      <td>0.578498</td>\n",
       "      <td>0.737699</td>\n",
       "      <td>0.720219</td>\n",
       "      <td>0.449580</td>\n",
       "      <td>0.622437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "name                GradientBoostingClassifier  LGBMClassifier  \\\n",
       "mtype                                                            \n",
       "[BACKWARD+MEAN]                       0.606686        0.753462   \n",
       "[BACKWARD+NEAREST]                    0.580423        0.737673   \n",
       "[NEAREST]                             0.578498        0.737699   \n",
       "\n",
       "name                RandomForestClassifier  SGDClassifier  XGBClassifier  \n",
       "mtype                                                                     \n",
       "[BACKWARD+MEAN]                   0.739342       0.425094       0.638578  \n",
       "[BACKWARD+NEAREST]                0.720495       0.437933       0.622540  \n",
       "[NEAREST]                         0.720219       0.449580       0.622437  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[result['ftype'] == '[CVFIT]'].pivot_table(index='mtype', columns='name', values='score')\n",
    "# result[result['ftype'] == '[WHOLE]'].pivot_table(index='mtype', columns='name', values='score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На параметрах по умолчанию наилучший результат показали LGBMClassifier и RandomForestClassifier.\n",
    "\n",
    "При этом метрика варьируется в зависимости от способа сопоставления фичей: вариант `backward + mean` эмпирически дает результат выше, а `backward + nearest` практически не отличается от `nearest`.<br>\n",
    "Предположение о сопоставлении фичей остается неизменным - профили пользователей, сформированные после даты коммерческого предложения вряд ли могли влиять на решение о покупке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GridSearchCV] [CVFIT] LGBMClassifier: 0.7530563403688264\n",
      "[GridSearchCV] [WHOLE] LGBMClassifier: 0.7581806893083856\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>GS score</th>\n",
       "      <th>CV score</th>\n",
       "      <th>WH score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.779205</td>\n",
       "      <td>0.753056</td>\n",
       "      <td>0.758181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model  GS score  CV score  WH score\n",
       "0  LGBMClassifier  0.779205  0.753056  0.758181"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preparer = make_pipeline(\n",
    "    Merger(features, method='backward', fillna='mean'),\n",
    "    TimeDifference('feats_time', 'train_time'),\n",
    "    Clusterer(['0', '1', '2'], n_clusters=8, random_state=13),\n",
    "    PurchaseRatio(by=['cluster']),\n",
    "    ColumnsCorrector('drop', ['id', 'train_time', 'feats_time']),\n",
    "    BasicFiller(strategy='mean', apply_on_fly=True),\n",
    ")\n",
    "\n",
    "estimators = [\n",
    "    # RandomForestClassifier(),\n",
    "    LGBMClassifier()\n",
    "]\n",
    "\n",
    "# =============================================================\n",
    "# grids = [\n",
    "#     {   # RandomForest grid\n",
    "#         'n_estimators': [50, 100, 150],\n",
    "#         'max_depth': [None, 3, 4, 6],\n",
    "#         'min_samples_leaf': [20, 31, 45],\n",
    "#     },\n",
    "#     # {   # LGBM grid\n",
    "#     #     'n_estimators': [50, 100, 150],\n",
    "#     #     'learning_rate': [0.05, 0.1, 0.2, 0.3],\n",
    "#     #     'max_depth': [-1, 4, 6],\n",
    "#     #     'num_leaves': [20, 31, 45, 60],\n",
    "#     # }\n",
    "# ]\n",
    "# =============================================================\n",
    "grids = [\n",
    "    {   # parameters grid\n",
    "        'random_state': [17,],                  # defaults\n",
    "        'n_jobs': [-1, ],                       # defaults\n",
    "        'class_weight': [class_weights, ],      # defaults\n",
    "        'n_estimators': [100, 125, 150, 200, 250],          # def=100\n",
    "        'learning_rate': [0.1, 0.15, 0.2, 0.25, 0.3],     # def=0.1\n",
    "        # 'max_depth': [0, *range(3, 8)],            # def=-1\n",
    "        'num_leaves': [5, 7, 11, 17, 23, 31],         # def=31\n",
    "    },\n",
    "]\n",
    "\n",
    "result, gscv = cv_compare(estimators, data, target, grids=grids, cv=folds, pipe=preparer, scorer=f1_macro, logger=logging)\n",
    "pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_ESTIMATOR = 0\n",
    "json.dump(gscv.best_params_, open(data_folder.joinpath('fit_params.json').as_posix(), 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## random_state stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RS] [CVFIT] LGBMClassifier: 0.7534708989679797\n",
      "[RS] [CVFIT] LGBMClassifier: 0.7534927827875061\n",
      "[RS] [CVFIT] LGBMClassifier: 0.7535103296103325\n",
      "[RS] [CVFIT] LGBMClassifier: 0.7536050895843791\n",
      "[RS] [CVFIT] LGBMClassifier: 0.7534743376190138\n",
      "[RS] [CVFIT] LGBMClassifier: 0.7534177384605752\n",
      "[RS] [CVFIT] LGBMClassifier: 0.7536418322991764\n",
      "Avg. RS metric: 0.7535161441898518\n"
     ]
    }
   ],
   "source": [
    "# check for random states stability\n",
    "N_RANGE = 7\n",
    "\n",
    "preparer = make_pipeline(\n",
    "    Merger(features, method='backward', fillna='mean'),\n",
    "    TimeDifference('feats_time', 'train_time'),    \n",
    "    Clusterer(['0', '1', '2'], n_clusters=8),\n",
    "    PurchaseRatio(by=['cluster']),\n",
    "    ColumnsCorrector('drop', ['id', 'train_time', 'feats_time',]),\n",
    "    BasicFiller(strategy='mean', apply_on_fly=True),\n",
    ")\n",
    "\n",
    "metrics = []\n",
    "for n in range(N_RANGE):\n",
    "    estimator = LGBMClassifier(n_jobs=-1, class_weight=class_weights,)\n",
    "    score, _, _ = cv_fit(estimator, preparer.fit_transform(data), target, cv=folds, scorer=f1_macro, logger=logging, prefix='[RS] [CVFIT]')\n",
    "    metrics.append(score)\n",
    "\n",
    "print(f'Avg. RS metric: {sum(metrics) / len(metrics)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d90a7511b44e26062c54f2bc9e753a4fcf24e14550b703ca1e7fb969fd68a2ad"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
