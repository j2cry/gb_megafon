## Зачача
Предсказание вероятности подключения услуги

## Данные
`data_train.csv` - набор тренировочных данных<br>
`data_test.csv` - набор тестовых данных<br>
`features.csv` - деперсонализированные профили пользователей<br>

## Параметры окружения
Python version: 3.9.5

## Описание результатов
`baseline.ipynb` - базовое решение, использующее все тренировочные данные и все фичи. Сопоставление фичей по ближайшей дате<br>
`research.ipynb` - исследование влияния PCA компрессии фичей<br>
`comparison.ipynb` - исследование без распределенных вычислений, использующее тренировочные данные после 19 ноября и уже сжатые фичи. Изучение вариантов сопоставления фичей, сравнение моделей, GridSearch<br>

`pyspark_pcs.ipynb` - черновик для сжатия фичей с помощью PySpark. Во всей работе используются фичи, сжатые именно этим способом<br>

## airflow
Сначала нужно запустить сам airflow. Сделать это можно по 
<a href="https://airflow.apache.org/docs/apache-airflow/stable/start/">официальной инструкции</a>.

При запуске в docker необходимо дополнительно расшарить папку для передачи данных в контейнер.
Также, необходимо добавить default filesystem connection и установить расширение apache-airflow-providers-apache-spark.

Мой вариант сборки airflow <a href="https://github.com/j2cry/local-airflow">здесь</a>.

Далее,
1. Содержимое папки `dags` скопировать/перенести/создать hard link в папку `dags/megafon`
2. Тренировочные данные и файл параметров модели скопировать/перенести/создать hard link в папку `data/megafon`
3. Запустить выполнение DAG
