## Зачача
Предсказание вероятности подключения услуги


## Параметры окружения
python version: 3.9.5<br>
airflow version: 2.3.1 on python 3.9.13


## Данные
`data_train.csv` - набор тренировочных данных<br>
`data_test.csv` - набор тестовых данных<br>
`features.csv` - деперсонализированные профили пользователей<br>


## Описание ноутбуков
`baseline.ipynb` - базовое решение, использующее все тренировочные данные и все фичи. Сопоставление фичей по ближайшей дате<br>
`research.ipynb` - исследование влияния PCA компрессии фичей<br>
`comparison.ipynb` - исследование без распределенных вычислений, использующее тренировочные данные после 19 ноября и уже сжатые фичи. Изучение вариантов сопоставления фичей, сравнение моделей, GridSearch<br>
`features.ipynb` - изучение набора пользовательских профилей<br>
`FE.ipynb` - разработка и проверка фичей<br>
`check.ipynb` - проверка работоспособности сохраненной модели<br>

`pyspark_pca.ipynb` - черновик для сжатия фичей с помощью PySpark. Во всей работе используются фичи, сжатые именно этим способом<br>


## Структура модели
`model.zip` - архивированная модель, включающая весь цикл подготовки данных<br>
`transformers.py` - набор используемых трансформеров; обязательно должен лежать рядом с файлом модели<br>
`predict.py` - CLI приложение для получения прогноза<br>


## airflow
Сначала нужно запустить сам airflow. Сделать это можно по 
<a href="https://airflow.apache.org/docs/apache-airflow/stable/start/">официальной инструкции</a>.

При запуске в docker необходимо дополнительно расшарить папку для передачи данных в контейнер.
Также, необходимо добавить default filesystem connection и установить расширение apache-airflow-providers-apache-spark.

Мой вариант сборки airflow <a href="https://github.com/j2cry/local-airflow">здесь</a>.

Далее,
1. Содержимое папки `dags` скопировать/перенести/создать hard link в папку `dags/megafon`
2. Тренировочные данные и файл параметров модели скопировать/перенести/создать hard link в папку `data/megafon`
3. Запустить выполнение DAG
